{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eghib22/I-m-Something-of-a-Painter-Myself/blob/main/CycleGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install kaggle\n",
        "! pip install wandb\n",
        "import wandb\n",
        "wandb.login(key=\"3a8d716177f04f9862b6cefb18e6d97955122204\")\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from google.colab import files\n",
        "DRIVE_KAGGLE_PATH = '/content/drive/MyDrive/kaggle.json'\n",
        "\n",
        "! mkdir -p ~/.kaggle\n",
        "! cp \"{DRIVE_KAGGLE_PATH}\" ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!ls -l ~/.kaggle/\n",
        "!kaggle competitions download -c gan-getting-started\n",
        "!unzip -o -q gan-getting-started.zip -d data\n",
        "!ls data\n",
        "import os\n",
        "import random\n",
        "import itertools\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aASlmaoX-BT2",
        "outputId": "ad5efe68-d866-4ad6-9c8e-241a72ab295c",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.11.12)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (0.23.1)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb) (8.3.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (3.1.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from wandb) (25.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb) (4.5.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.12.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from wandb) (6.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.32.4)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.47.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.12/dist-packages (from wandb) (4.15.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2025.11.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into https://api.wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find your API key here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33meghib22\u001b[0m (\u001b[33meghib22-free-university-of-tbilisi-\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "total 4\n",
            "-rw------- 1 root root 74 Dec 25 00:42 kaggle.json\n",
            "Downloading gan-getting-started.zip to /content\n",
            " 84% 307M/367M [00:03<00:00, 77.3MB/s]\n",
            "100% 367M/367M [00:03<00:00, 99.7MB/s]\n",
            "monet_jpg  monet_tfrec\tphoto_jpg  photo_tfrec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Config:\n",
        "    image_size = 256\n",
        "    batch_size = 1\n",
        "    num_workers = 2\n",
        "    lr = 2e-4\n",
        "    epochs = 60\n",
        "    lambda_cycle = 11.0\n",
        "    lambda_identity = 2.0\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "cfg = Config()\n",
        "\n",
        "class MonetPhotoDataset(Dataset):\n",
        "    def __init__(self, monet_dir, photo_dir, transform=None):\n",
        "        self.monet_paths = sorted(os.listdir(monet_dir))\n",
        "        self.photo_paths = sorted(os.listdir(photo_dir))\n",
        "        self.monet_dir = monet_dir\n",
        "        self.photo_dir = photo_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.monet_paths)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        monet_path = os.path.join(\n",
        "            self.monet_dir,\n",
        "            self.monet_paths[idx % len(self.monet_paths)]\n",
        "        )\n",
        "        photo_path = os.path.join(\n",
        "            self.photo_dir,\n",
        "            self.photo_paths[random.randint(0, len(self.photo_paths) - 1)]\n",
        "        )\n",
        "\n",
        "        monet = Image.open(monet_path).convert(\"RGB\")\n",
        "        photo = Image.open(photo_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            monet = self.transform(monet)\n",
        "            photo = self.transform(photo)\n",
        "\n",
        "        return {\"monet\": monet, \"photo\": photo}\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(286),\n",
        "    transforms.RandomCrop(cfg.image_size),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "dataset = MonetPhotoDataset(\n",
        "    \"data/monet_jpg\",\n",
        "    \"data/photo_jpg\",\n",
        "    transform\n",
        ")\n",
        "\n",
        "loader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=cfg.batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=cfg.num_workers\n",
        ")\n",
        "fixed_batch = next(iter(loader))\n",
        "fixed_photo = fixed_batch[\"photo\"].to(cfg.device)"
      ],
      "metadata": {
        "id": "O6kjznkfGM29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def save_samples(epoch):\n",
        "    G.eval()\n",
        "    # fixed_photo was already moved to device in cell O6kjznkfGM29\n",
        "    # fixed_photo has shape [batch_size, channels, height, width]\n",
        "    # We want to show the first 4 real photos and their generated Monet versions.\n",
        "    real_photos_to_display = fixed_photo[:4]\n",
        "    fake_monets_to_display = G(real_photos_to_display) # Generate from the same real photos\n",
        "\n",
        "    # Concatenate real photos and fake monets vertically for display\n",
        "    # This will result in 4 real photos on the top row and 4 fake monets on the bottom row\n",
        "    combined_images = torch.cat([real_photos_to_display, fake_monets_to_display], dim=0)\n",
        "\n",
        "    grid = make_grid(combined_images, nrow=4, normalize=True) # 4 images per row\n",
        "    plt.figure(figsize=(8, 6)) # Adjust figure size for two rows\n",
        "    plt.imshow(grid.permute(1, 2, 0).cpu())\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"Epoch {epoch} - Original Photos (Top) and Generated Monets (Bottom)\")\n",
        "    G.train()\n",
        "class ResnetBlock(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(dim, dim, 3),\n",
        "            nn.InstanceNorm2d(dim),\n",
        "            nn.ReLU(True),\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(dim, dim, 3),\n",
        "            nn.InstanceNorm2d(dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.block(x)\n",
        "class ResnetGenerator(nn.Module):\n",
        "    def __init__(self, input_nc=3, output_nc=3, n_blocks=10):\n",
        "        super().__init__()\n",
        "\n",
        "        model = [\n",
        "            nn.ReflectionPad2d(3),\n",
        "            nn.Conv2d(input_nc, 64, 7),\n",
        "            nn.InstanceNorm2d(64),\n",
        "            nn.ReLU(True)\n",
        "        ]\n",
        "\n",
        "        # Downsample\n",
        "        in_features = 64\n",
        "        for _ in range(2):\n",
        "            model += [\n",
        "                nn.Conv2d(in_features, in_features * 2, 3, stride=2, padding=1),\n",
        "                nn.InstanceNorm2d(in_features * 2),\n",
        "                nn.ReLU(True)\n",
        "            ]\n",
        "            in_features *= 2\n",
        "\n",
        "        # Residual blocks\n",
        "        for _ in range(n_blocks):\n",
        "            model += [ResnetBlock(in_features)]\n",
        "\n",
        "        # Upsample\n",
        "        for _ in range(2):\n",
        "            model += [\n",
        "                nn.ConvTranspose2d(in_features, in_features // 2, 3, stride=2,\n",
        "                                   padding=1, output_padding=1),\n",
        "                nn.InstanceNorm2d(in_features // 2),\n",
        "                nn.ReLU(True)\n",
        "            ]\n",
        "            in_features //= 2\n",
        "\n",
        "        model += [\n",
        "            nn.ReflectionPad2d(3),\n",
        "            nn.Conv2d(64, output_nc, 7),\n",
        "            nn.Tanh()\n",
        "        ]\n",
        "\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "id": "PN3B97zqGTdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchDiscriminator(nn.Module):\n",
        "    def __init__(self, input_nc=3):\n",
        "        super().__init__()\n",
        "\n",
        "        def block(in_c, out_c, stride=2, norm=True):\n",
        "            layers = [nn.Conv2d(in_c, out_c, 4, stride=stride, padding=1)]\n",
        "            if norm:\n",
        "                layers.append(nn.InstanceNorm2d(out_c))\n",
        "            layers.append(nn.LeakyReLU(0.2, True))\n",
        "            return layers\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *block(input_nc, 64, norm=False),\n",
        "            *block(64, 128),\n",
        "            *block(128, 256),\n",
        "            *block(256, 512, stride=1),\n",
        "            nn.Conv2d(512, 1, 4, padding=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "class LSGANLoss:\n",
        "    def __init__(self):\n",
        "        self.loss = nn.MSELoss()\n",
        "\n",
        "    def __call__(self, preds, target_is_real):\n",
        "        if target_is_real:\n",
        "            target = torch.ones_like(preds)\n",
        "        else:\n",
        "            target = torch.zeros_like(preds)\n",
        "        return self.loss(preds, target)\n",
        "cycle_loss_fn = nn.L1Loss()\n",
        "identity_loss_fn = nn.L1Loss()\n",
        "gan_loss_fn = LSGANLoss()\n",
        "G = ResnetGenerator().to(cfg.device)  # Photo ‚Üí Monet\n",
        "F = ResnetGenerator().to(cfg.device)  # Monet ‚Üí Photo\n",
        "\n",
        "D_monet = PatchDiscriminator().to(cfg.device)\n",
        "D_photo = PatchDiscriminator().to(cfg.device)\n",
        "def init_weights(m):\n",
        "    if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "        if m.bias is not None:\n",
        "            nn.init.constant_(m.bias.data, 0)\n",
        "    elif isinstance(m, nn.InstanceNorm2d):\n",
        "        if m.weight is not None:\n",
        "            nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        if m.bias is not None:\n",
        "            nn.init.constant_(m.bias.data, 0)\n",
        "\n",
        "G.apply(init_weights)\n",
        "F.apply(init_weights)\n",
        "D_monet.apply(init_weights)\n",
        "D_photo.apply(init_weights)\n"
      ],
      "metadata": {
        "id": "EP_HF2DHGYjN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87eed7de-b1d8-4557-a91c-a6b446bfb743"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PatchDiscriminator(\n",
              "  (model): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "    (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
              "    (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir = \"/content/drive/MyDrive/checkpoints\"\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "start_epoch = 0\n",
        "\n",
        "g_path = os.path.join(checkpoint_dir, \"G_latest.pth\")\n",
        "f_path = os.path.join(checkpoint_dir, \"F_latest.pth\")\n",
        "\n",
        "if os.path.exists(g_path) and os.path.exists(f_path):\n",
        "    print(\"üîÅ Resuming from latest checkpoint\")\n",
        "    G.load_state_dict(torch.load(g_path, map_location=cfg.device), strict=False)\n",
        "    F.load_state_dict(torch.load(f_path, map_location=cfg.device), strict=False)\n",
        "class ImagePool:\n",
        "    def __init__(self, pool_size=50):\n",
        "        self.pool_size = pool_size\n",
        "        self.images = []\n",
        "\n",
        "    def query(self, images):\n",
        "        result = []\n",
        "        for image in images:\n",
        "            image = image.unsqueeze(0)\n",
        "            if len(self.images) < self.pool_size:\n",
        "                self.images.append(image)\n",
        "                result.append(image)\n",
        "            else:\n",
        "                if random.random() > 0.5:\n",
        "                    idx = random.randint(0, self.pool_size - 1)\n",
        "                    tmp = self.images[idx].clone()\n",
        "                    self.images[idx] = image\n",
        "                    result.append(tmp)\n",
        "                else:\n",
        "                    result.append(image)\n",
        "        return torch.cat(result, dim=0)\n",
        "\n",
        "fake_monet_pool = ImagePool(50)\n",
        "fake_photo_pool = ImagePool(50)\n"
      ],
      "metadata": {
        "id": "AWiuOHOAtMFU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9969aaae-647c-4c6e-b837-0022930bf3db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÅ Resuming from latest checkpoint\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_batches = len(loader)\n",
        "\n",
        "# Define Optimizers\n",
        "g_optimizer = torch.optim.Adam(itertools.chain(G.parameters(), F.parameters()), lr=cfg.lr, betas=(0.5, 0.999))\n",
        "d_monet_optimizer = torch.optim.Adam(D_monet.parameters(), lr=cfg.lr, betas=(0.5, 0.999))\n",
        "d_photo_optimizer = torch.optim.Adam(D_photo.parameters(), lr=cfg.lr, betas=(0.5, 0.999))\n",
        "\n",
        "wandb.init(project=\"cyclegan_monet_photos\", config=cfg)\n",
        "\n",
        "for epoch in range(cfg.epochs):\n",
        "    print(f\"\\nüöÄ Starting epoch {epoch+1}/{cfg.epochs}\")\n",
        "\n",
        "    for i, batch in enumerate(loader):\n",
        "        real_monet = batch[\"monet\"].to(cfg.device)\n",
        "        real_photo = batch[\"photo\"].to(cfg.device)\n",
        "\n",
        "        # =========================\n",
        "        # Train Generators\n",
        "        # =========================\n",
        "        g_optimizer.zero_grad()\n",
        "\n",
        "        fake_monet = G(real_photo)\n",
        "        rec_photo = F(fake_monet)\n",
        "\n",
        "        fake_photo = F(real_monet)\n",
        "        rec_monet = G(fake_photo)\n",
        "\n",
        "        loss_g_photo = gan_loss_fn(D_monet(fake_monet), True)\n",
        "        loss_g_monet = gan_loss_fn(D_photo(fake_photo), True)\n",
        "\n",
        "        loss_cycle = (\n",
        "            cycle_loss_fn(rec_photo, real_photo) +\n",
        "            cycle_loss_fn(rec_monet, real_monet)\n",
        "        ) * cfg.lambda_cycle\n",
        "\n",
        "        id_photo = F(real_photo)\n",
        "        id_monet = G(real_monet)\n",
        "\n",
        "        loss_identity = (\n",
        "            identity_loss_fn(id_photo, real_photo) +\n",
        "            identity_loss_fn(id_monet, real_monet)\n",
        "        ) * cfg.lambda_identity\n",
        "\n",
        "        loss_G = loss_g_photo + loss_g_monet + loss_cycle + loss_identity\n",
        "        loss_G.backward()\n",
        "        g_optimizer.step()\n",
        "\n",
        "        # =========================\n",
        "        # Train Discriminator Monet\n",
        "        # =========================\n",
        "        d_monet_optimizer.zero_grad()\n",
        "\n",
        "        loss_d_monet_real = gan_loss_fn(D_monet(real_monet), True)\n",
        "        fake_monet_buffer = fake_monet_pool.query(fake_monet.detach())\n",
        "        loss_d_monet_fake = gan_loss_fn(D_monet(fake_monet_buffer), False)\n",
        "\n",
        "        loss_D_monet = (loss_d_monet_real + loss_d_monet_fake) * 0.5\n",
        "\n",
        "        loss_D_monet.backward()\n",
        "        d_monet_optimizer.step()\n",
        "\n",
        "        # =========================\n",
        "        # Train Discriminator Photo\n",
        "        # =========================\n",
        "        d_photo_optimizer.zero_grad()\n",
        "\n",
        "        loss_d_photo_real = gan_loss_fn(D_photo(real_photo), True)\n",
        "        fake_photo_buffer = fake_photo_pool.query(fake_photo.detach())\n",
        "        loss_d_photo_fake = gan_loss_fn(D_photo(fake_photo_buffer), False)\n",
        "\n",
        "        loss_D_photo = (loss_d_photo_real + loss_d_photo_fake) * 0.5\n",
        "\n",
        "        loss_D_photo.backward()\n",
        "        d_photo_optimizer.step()\n",
        "\n",
        "        # =========================\n",
        "        # Logging + PRINTS\n",
        "        # =========================\n",
        "        if i % 100 == 0:\n",
        "            print(\n",
        "                f\"[Epoch {epoch+1}/{cfg.epochs}] \"\n",
        "                f\"[Batch {i}/{num_batches}] \"\n",
        "                f\"G: {loss_G.item():.3f} | \"\n",
        "                f\"Cycle: {loss_cycle.item():.3f} | \"\n",
        "                f\"Id: {loss_identity.item():.3f} | \"\n",
        "                f\"D_M: {loss_D_monet.item():.3f} | \"\n",
        "                f\"D_P: {loss_D_photo.item():.3f}\"\n",
        "            )\n",
        "\n",
        "            wandb.log({\n",
        "                \"loss_G\": loss_G.item(),\n",
        "                \"loss_cycle\": loss_cycle.item(),\n",
        "                \"loss_identity\": loss_identity.item(),\n",
        "                \"loss_D_monet\": loss_D_monet.item(),\n",
        "                \"loss_D_photo\": loss_D_photo.item(),\n",
        "                \"epoch\": epoch,\n",
        "                \"step\": epoch * num_batches + i\n",
        "            })\n",
        "    save_samples(epoch)\n",
        "    torch.save(G.state_dict(), f\"{checkpoint_dir}/G_latest.pth\")\n",
        "    torch.save(F.state_dict(), f\"{checkpoint_dir}/F_latest.pth\")\n",
        "\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "loqXjvFdGxDV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4b3eeb49-0c32-483d-9f3c-8f654df05350"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ</td></tr><tr><td>loss_D_monet</td><td>‚ñÅ</td></tr><tr><td>loss_D_photo</td><td>‚ñÅ</td></tr><tr><td>loss_G</td><td>‚ñÅ</td></tr><tr><td>loss_cycle</td><td>‚ñÅ</td></tr><tr><td>loss_identity</td><td>‚ñÅ</td></tr><tr><td>step</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>loss_D_monet</td><td>1.99684</td></tr><tr><td>loss_D_photo</td><td>1.28422</td></tr><tr><td>loss_G</td><td>7.0007</td></tr><tr><td>loss_cycle</td><td>2.34911</td></tr><tr><td>loss_identity</td><td>0.39424</td></tr><tr><td>step</td><td>0</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">winter-pond-10</strong> at: <a href='https://wandb.ai/eghib22-free-university-of-tbilisi-/cyclegan_monet_photos/runs/0m84kiw6' target=\"_blank\">https://wandb.ai/eghib22-free-university-of-tbilisi-/cyclegan_monet_photos/runs/0m84kiw6</a><br> View project at: <a href='https://wandb.ai/eghib22-free-university-of-tbilisi-/cyclegan_monet_photos' target=\"_blank\">https://wandb.ai/eghib22-free-university-of-tbilisi-/cyclegan_monet_photos</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251225_004245-0m84kiw6/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251225_004420-vk06pzns</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/eghib22-free-university-of-tbilisi-/cyclegan_monet_photos/runs/vk06pzns' target=\"_blank\">curious-cherry-11</a></strong> to <a href='https://wandb.ai/eghib22-free-university-of-tbilisi-/cyclegan_monet_photos' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/eghib22-free-university-of-tbilisi-/cyclegan_monet_photos' target=\"_blank\">https://wandb.ai/eghib22-free-university-of-tbilisi-/cyclegan_monet_photos</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/eghib22-free-university-of-tbilisi-/cyclegan_monet_photos/runs/vk06pzns' target=\"_blank\">https://wandb.ai/eghib22-free-university-of-tbilisi-/cyclegan_monet_photos/runs/vk06pzns</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üöÄ Starting epoch 1/60\n",
            "[Epoch 1/60] [Batch 0/300] G: 5.068 | Cycle: 3.256 | Id: 0.682 | D_M: 0.598 | D_P: 0.431\n",
            "[Epoch 1/60] [Batch 100/300] G: 4.976 | Cycle: 3.438 | Id: 0.614 | D_M: 0.298 | D_P: 0.289\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1050395530.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mloss_G\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_g_photo\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_g_monet\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_cycle\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_identity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mloss_G\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mg_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             )\n\u001b[0;32m--> 625\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    626\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9krrZYscnilN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}